# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

agent:
  consumer:
    model:
      hidden_dims:
        - 16
        - 8
      output_dim: 100
      activation: 
      softmax: false
      batch_norm: true
      skip_connection: false
      head: true
      dropout_p: 0.0
    optimization:
      optim_cls: rmsprop
      optim_params:
        lr: 0.001
    algorithm:
      reward_discount: .9
      train_iters: 10
      batch_size: 128
      loss_cls: mse
      target_update_freq: 5
      soft_update_coefficient: 0.1
      double: false
    experience_memory:
      experience_memory_size: 50000
      experience_memory_overwrite_type: random
      flush_experience_memory_after_step: false
      min_new_experiences_to_trigger_learning: 1000000
      min_experience_memory_size: 10
  producer:
    model:
      hidden_dims:
        - 16
        - 8
      output_dim: 10
      activation: 
      softmax: false
      batch_norm: true
      skip_connection: false
      head: true
      dropout_p: 0.0
    optimization:
      optim_cls: rmsprop
      optim_params:
        lr: 0.001
    algorithm:
      reward_discount: .9
      train_iters: 10
      batch_size: 128
      loss_cls: mse
      target_update_freq: 5
      soft_update_coefficient: 0.1
      double: false
    experience_memory:
      experience_memory_size: 50000
      experience_memory_overwrite_type: random
      flush_experience_memory_after_step: false
      min_new_experiences_to_trigger_learning: 1000000
      min_experience_memory_size: 10
training: 
  env: 
    scenario: supply_chain
    topology: random
    durations: 250
  max_episode: 1
  agent_update_interval: 50
  exploration:
    parameter_names:
      - epsilon
    start: 0.4
    end: 0.0
distributed:
  group: sc-dqn
  num_actors: 8
  redis_host: maro-sc
  redis_port: 6379
  required_actor_finishes: 8
